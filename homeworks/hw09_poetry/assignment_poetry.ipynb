{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox81bxE_CvJM"
      },
      "source": [
        "## Домашнее задание №9\n",
        "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
        "\n",
        "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Vov_ryjhCvJN"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import string\n",
        "import os\n",
        "from random import sample\n",
        "\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nGhZy79aCvJO",
        "outputId": "6ca22237-8284-4475-a978-0727f87540fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu device is available\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"{} device is available\".format(device))\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPenWOy01Ooa",
        "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
      },
      "source": [
        "#### 1. Загрузка данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0yOCvfxcCvJO",
        "outputId": "44b16fb2-717f-480f-c0dd-4a526ff4e237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-18 16:11:47--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt.1’\n",
            "\n",
            "onegin.txt.1        100%[===================>] 256.37K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-11-18 16:11:47 (6.90 MB/s) - ‘onegin.txt.1’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
        "\n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQYpmGfR_gJ8"
      },
      "source": [
        "#### 2. Построение словаря и предобработка текста\n",
        "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lJ4hADmqCvJP",
        "outputId": "13669972-c332-4ad9-ec03-09cda8fe4ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "tokens = sorted(set(text.lower())) + [\"<sos>\"]\n",
        "num_tokens = len(tokens)\n",
        "\n",
        "assert num_tokens == 84, \"Check the tokenization process\"\n",
        "\n",
        "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
        "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
        "\n",
        "print(\"Seems fine!\")\n",
        "\n",
        "\n",
        "text_encoded = [token_to_idx[x] for x in text]\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYPE2ISECvJP"
      },
      "source": [
        "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
        "\n",
        "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
        "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
        "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
        "\n",
        "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
        "\n",
        "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6PBZ0wLNCvJQ"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "batch_size = 256\n",
        "seq_length = 100\n",
        "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx[\"<sos>\"]\n",
        "\n",
        "\n",
        "def generate_chunk():\n",
        "    global text_encoded, start_column, batch_size, seq_length\n",
        "\n",
        "    start_index = np.random.randint(0, len(text_encoded) - batch_size * seq_length - 1)\n",
        "    data = np.array(\n",
        "        text_encoded[start_index : start_index + batch_size * seq_length]\n",
        "    ).reshape((batch_size, -1))\n",
        "    yield np.hstack((start_column, data))\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzAItEjaCvJQ"
      },
      "source": [
        "Пример батча:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "eXe9j3RoCvJR",
        "outputId": "8fcfc656-b0c7-442b-bb96-20254bef6a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[83, 61, 50, ..., 63, 45, 76],\n",
              "       [83,  1, 51, ..., 50, 54,  1],\n",
              "       [83, 68, 45, ..., 56, 73,  1],\n",
              "       ...,\n",
              "       [83, 64, 55, ..., 58, 59,  1],\n",
              "       [83, 74, 63, ..., 53, 56, 62],\n",
              "       [83, 76,  1, ..., 47, 72, 66]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "next(generate_chunk())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOHF-5-wCvJR"
      },
      "source": [
        "Далее вам предстоит написать код для обучения модели и генерации текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NFPhvOT1CvJR"
      },
      "outputs": [],
      "source": [
        "# your beautiful experiments here\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Инициализация скрытых состояний\n",
        "        return torch.zeros(1, batch_size, hidden_dim)\n",
        "\n",
        "# Параметры модели\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "vocab_size = len(tokens)\n",
        "\n",
        "# Создаем модель\n",
        "model = CharRNN(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ptswGICvJS"
      },
      "source": [
        "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Q6mitJ4gCvJS",
        "outputId": "ebcec32e-5ff2-49ef-896c-045a9f780cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 256 and the array at index 1 has size 64",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-3cc481be413d>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Обучаем модель\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-3cc481be413d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Подготовка данных для обучения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-6ac965a8c12a>\u001b[0m in \u001b[0;36mgenerate_chunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtext_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     ).reshape((batch_size, -1))\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32myield\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 256 and the array at index 1 has size 64"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.002\n",
        "num_epochs = 20\n",
        "# Функция для обучения модели\n",
        "def train_model():\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "\n",
        "        for batch in generate_chunk():\n",
        "            # Подготовка данных для обучения\n",
        "            inputs = torch.tensor(batch[:, :-1], dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(batch[:, 1:], dtype=torch.long).to(device)\n",
        "\n",
        "            # Обнуляем градиенты\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Прогоняем модель\n",
        "            output, hidden = model(inputs, hidden)\n",
        "\n",
        "            # Вычисляем потери\n",
        "            loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Обратное распространение и обновление весов\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Печатаем потери на каждой эпохе\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(generate_chunk()):.4f}\")\n",
        "\n",
        "        # Очистим вывод в Jupyter\n",
        "        clear_output(wait=True)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Обучаем модель\n",
        "model = train_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBEgpZeTCvJS"
      },
      "source": [
        "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbw8VmTsCvJS"
      },
      "outputs": [],
      "source": [
        "def generate_sample(\n",
        "    char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device\n",
        "):\n",
        "    \"\"\"\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    \"\"\"\n",
        "\n",
        "    if seed_phrase is not None:\n",
        "        x_sequence = [token_to_idx[\"<sos>\"]] + [\n",
        "            token_to_idx[token] for token in seed_phrase\n",
        "        ]\n",
        "    else:\n",
        "        x_sequence = [token_to_idx[\"<sos>\"]]\n",
        "\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64).to(device)\n",
        "\n",
        "    # feed the seed phrase, if any\n",
        "\n",
        "    # your code here\n",
        "\n",
        "    return \"\".join([tokens[ix] for ix in x_sequence.cpu().data.numpy()[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09K6f0r2CvJS"
      },
      "source": [
        "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiQ9zxuGCvJS",
        "outputId": "ad30474b-b813-4af4-e77c-fbe78388e485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> мой дядя самых честных правилас;\n",
            "\n",
            "\n",
            "\n",
            "xiv\n",
            "\n",
            "но как потокой.\n",
            "\n",
            "\n",
            "\n",
            "xii\n",
            "\n",
            "«я свобред не словавран в скорей,\n",
            "для с посвялесь мне моловой,\n",
            "те ты,\n",
            "перегиной в тям праздной\n",
            "и привезут перваю вся вновся сквозь ти стала сблился,\n",
            "и старый свимарной таня обратель любова не когда и нет волностье нежной\n",
            "тишен,\n",
            "перестоком.\n",
            "«поже постаничив очествы\n",
            "в и старько забаньем и заковенью,\n",
            "ее своя моднать наводушта;\n",
            "какой нет поли своем горозный и быле и, законно он ходушних недважный плая\n",
            "с за стра.\n",
            "\n",
            "\n",
            "\n",
            "xvii\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xxvi\n",
            "\n",
            "все \n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    generate_sample(\n",
        "        model, \" мой дядя самых честных правил\", max_length=500, temperature=0.8\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TeBYwwRCvJT"
      },
      "source": [
        "### Сдача задания\n",
        "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
        "\n",
        "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa0573znCvJT"
      },
      "outputs": [],
      "source": [
        "seed_phrase = \" мой дядя самых честных правил\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "proHYa4-CvJT"
      },
      "outputs": [],
      "source": [
        "generated_phrases = # your code here\n",
        "\n",
        "# For example:\n",
        "\n",
        "# generated_phrases = [\n",
        "#     generate_sample(\n",
        "#         model,\n",
        "#         ' мой дядя самых честных правил',\n",
        "#         max_length=500,\n",
        "#         temperature=1.\n",
        "#     ).replace('<sos>', '')\n",
        "#     for _ in range(10)\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08C9xIIuCvJT"
      },
      "outputs": [],
      "source": [
        "output = {key: ','.join([str(x) for x in list(data.item()[key])]) for key in 'train', 'test'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC6jexiwCvJT"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "if \"generated_phrases\" not in locals():\n",
        "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
        "\n",
        "for phrase in generated_phrases:\n",
        "\n",
        "    if not isinstance(phrase, str):\n",
        "        raise ValueError(\"The generated phrase should be a string\")\n",
        "\n",
        "    if len(phrase) != 500:\n",
        "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
        "\n",
        "    assert all(\n",
        "        [x in set(tokens) for x in set(list(phrase))]\n",
        "    ), \"Unknown tokens detected, check your submission!\"\n",
        "\n",
        "\n",
        "submission_dict = {\"token_to_idx\": token_to_idx, \"generated_phrases\": generated_phrases}\n",
        "\n",
        "np.save(\"submission_dict_hw09.npy\", submission_dict, allow_pickle=True)\n",
        "print(\"File saved to `submission_dict_hw09.npy`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g-syUoICvJT"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "NLP HW Lab01_Poetry_generation.v5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}